{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Into2AIML3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Munazir/Deep-Learning-with-TensorFlow/blob/master/Into2AIML3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WrlnJjSyMJ_9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "mJ3wyBpQMMHW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  Fashion MNIST Classification\n",
        "\n",
        "Lets classify the fashion data into 10 categories"
      ]
    },
    {
      "metadata": {
        "id": "80ewnT4bMWeK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2f7b1b8-655a-45bc-b402-457d9458ce71"
      },
      "cell_type": "code",
      "source": [
        "## Import the necessary libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LnRzN_1OMnMQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## import the fashion Mnist data from Keras dataset\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFFaMj6t3apF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fc0cb5c7-62ff-416f-85fe-f98c529b9317"
      },
      "cell_type": "code",
      "source": [
        "fashion_mnist"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'tensorflow._api.v1.keras.datasets.fashion_mnist' from '/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v1/keras/datasets/fashion_mnist/__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "xKzcGS7L3dXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "78fac89a-d5b6-4e9c-cc11-bb955c9a68d2"
      },
      "cell_type": "code",
      "source": [
        "## load the data into environmet\n",
        "(train_feature,train_label),(test_feature,test_label) = fashion_mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0xZ2jDWV3v3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "3d2d1ab6-06fe-490d-812f-66f5d21a62b5"
      },
      "cell_type": "code",
      "source": [
        "## Explore the data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_feature[42])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe893ed3b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlgBg8D8oLtVmornzUgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "D9Fj_zpG4ch2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "743584fb-f32a-4122-aa10-b7f08dd902a3"
      },
      "cell_type": "code",
      "source": [
        "## checking the numerical images\n",
        "print(train_feature[42])\n",
        "print(train_label[42])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  82 187\n",
            "   26   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0   0 179 240 237\n",
            "  255 240 139  83  64  43  60  54   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0  58 239 222 234\n",
            "  238 246 252 254 255 248 255 187   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   2   3   0   0 194 239 226 237\n",
            "  235 232 230 234 234 233 249 171   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   0   0  10 255 226 242 239\n",
            "  238 239 240 239 242 238 248 192   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 172 245 229 240 241\n",
            "  240 241 243 243 241 227 250 209   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   6   5   0  62 255 230 236 239 241\n",
            "  242 241 242 242 238 238 242 253   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   3   0   0 255 235 228 244 241 241\n",
            "  244 243 243 244 243 239 235 255  22   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 246 228 220 245 243 237 241\n",
            "  242 242 242 243 239 237 235 253 106   0]\n",
            " [  0   0   3   4   4   2   1   0   0  18 243 228 231 241 243 237 238 242\n",
            "  241 240 240 240 235 237 236 246 234   0]\n",
            " [  1   0   0   0   0   0   0   0  22 255 238 227 238 239 237 241 241 237\n",
            "  236 238 239 239 239 239 239 237 255   0]\n",
            " [  0   0   0   0   0  25  83 168 255 225 225 235 228 230 227 225 227 231\n",
            "  232 237 240 236 238 239 239 235 251  62]\n",
            " [  0 165 225 220 224 255 255 233 229 223 227 228 231 232 235 237 233 230\n",
            "  228 230 233 232 235 233 234 235 255  58]\n",
            " [ 52 251 221 226 227 225 225 225 226 226 225 227 231 229 232 239 245 250\n",
            "  251 252 254 254 252 254 252 235 255   0]\n",
            " [ 31 208 230 233 233 237 236 236 241 235 241 247 251 254 242 236 233 227\n",
            "  219 202 193 189 186 181 171 165 190  42]\n",
            " [ 77 199 172 188 199 202 218 219 220 229 234 222 213 209 207 210 203 184\n",
            "  152 171 165 162 162 167 168 157 192  78]\n",
            " [  0  45 101 140 159 174 182 186 185 188 195 197 188 175 133  70  19   0\n",
            "    0 209 231 218 222 224 227 217 229  93]\n",
            " [  0   0   0   0   0   0   2  24  37  45  32  18  11   0   0   0   0   0\n",
            "    0  72  51  53  37  34  29  31   5   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OOlYL8XT4yL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecea3d07-f372-4c5e-9aeb-50b526157c03"
      },
      "cell_type": "code",
      "source": [
        "## checking the unique labels in the data\n",
        "set(train_label.tolist())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "eH1RiGC-5RRs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Since the image has the pixel values which ranges from 0 to 255 so to train the Neural Network model lets normalise the data\n",
        "\n",
        "train_feature = train_feature/255.0\n",
        "test_feature = test_feature/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pevhb6QS6OiF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2481
        },
        "outputId": "e16ccec1-d6a7-48d0-c0f3-8e5b375e7e63"
      },
      "cell_type": "code",
      "source": [
        "## cheking the data after normalisation\n",
        "print(train_feature[42])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.32156863 0.73333333\n",
            "  0.10196078 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.         0.\n",
            "  0.00392157 0.         0.         0.70196078 0.94117647 0.92941176\n",
            "  1.         0.94117647 0.54509804 0.3254902  0.25098039 0.16862745\n",
            "  0.23529412 0.21176471 0.         0.00392157]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.         0.\n",
            "  0.00392157 0.         0.22745098 0.9372549  0.87058824 0.91764706\n",
            "  0.93333333 0.96470588 0.98823529 0.99607843 1.         0.97254902\n",
            "  1.         0.73333333 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.00784314 0.01176471\n",
            "  0.         0.         0.76078431 0.9372549  0.88627451 0.92941176\n",
            "  0.92156863 0.90980392 0.90196078 0.91764706 0.91764706 0.91372549\n",
            "  0.97647059 0.67058824 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.00392157 0.00392157 0.\n",
            "  0.         0.03921569 1.         0.88627451 0.94901961 0.9372549\n",
            "  0.93333333 0.9372549  0.94117647 0.9372549  0.94901961 0.93333333\n",
            "  0.97254902 0.75294118 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.6745098  0.96078431 0.89803922 0.94117647 0.94509804\n",
            "  0.94117647 0.94509804 0.95294118 0.95294118 0.94509804 0.89019608\n",
            "  0.98039216 0.81960784 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.02352941 0.01960784 0.\n",
            "  0.24313725 1.         0.90196078 0.9254902  0.9372549  0.94509804\n",
            "  0.94901961 0.94509804 0.94901961 0.94901961 0.93333333 0.93333333\n",
            "  0.94901961 0.99215686 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.01176471 0.         0.\n",
            "  1.         0.92156863 0.89411765 0.95686275 0.94509804 0.94509804\n",
            "  0.95686275 0.95294118 0.95294118 0.95686275 0.95294118 0.9372549\n",
            "  0.92156863 1.         0.08627451 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.96470588\n",
            "  0.89411765 0.8627451  0.96078431 0.95294118 0.92941176 0.94509804\n",
            "  0.94901961 0.94901961 0.94901961 0.95294118 0.9372549  0.92941176\n",
            "  0.92156863 0.99215686 0.41568627 0.        ]\n",
            " [0.         0.         0.01176471 0.01568627 0.01568627 0.00784314\n",
            "  0.00392157 0.         0.         0.07058824 0.95294118 0.89411765\n",
            "  0.90588235 0.94509804 0.95294118 0.92941176 0.93333333 0.94901961\n",
            "  0.94509804 0.94117647 0.94117647 0.94117647 0.92156863 0.92941176\n",
            "  0.9254902  0.96470588 0.91764706 0.        ]\n",
            " [0.00392157 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.08627451 1.         0.93333333 0.89019608\n",
            "  0.93333333 0.9372549  0.92941176 0.94509804 0.94509804 0.92941176\n",
            "  0.9254902  0.93333333 0.9372549  0.9372549  0.9372549  0.9372549\n",
            "  0.9372549  0.92941176 1.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.09803922\n",
            "  0.3254902  0.65882353 1.         0.88235294 0.88235294 0.92156863\n",
            "  0.89411765 0.90196078 0.89019608 0.88235294 0.89019608 0.90588235\n",
            "  0.90980392 0.92941176 0.94117647 0.9254902  0.93333333 0.9372549\n",
            "  0.9372549  0.92156863 0.98431373 0.24313725]\n",
            " [0.         0.64705882 0.88235294 0.8627451  0.87843137 1.\n",
            "  1.         0.91372549 0.89803922 0.8745098  0.89019608 0.89411765\n",
            "  0.90588235 0.90980392 0.92156863 0.92941176 0.91372549 0.90196078\n",
            "  0.89411765 0.90196078 0.91372549 0.90980392 0.92156863 0.91372549\n",
            "  0.91764706 0.92156863 1.         0.22745098]\n",
            " [0.20392157 0.98431373 0.86666667 0.88627451 0.89019608 0.88235294\n",
            "  0.88235294 0.88235294 0.88627451 0.88627451 0.88235294 0.89019608\n",
            "  0.90588235 0.89803922 0.90980392 0.9372549  0.96078431 0.98039216\n",
            "  0.98431373 0.98823529 0.99607843 0.99607843 0.98823529 0.99607843\n",
            "  0.98823529 0.92156863 1.         0.        ]\n",
            " [0.12156863 0.81568627 0.90196078 0.91372549 0.91372549 0.92941176\n",
            "  0.9254902  0.9254902  0.94509804 0.92156863 0.94509804 0.96862745\n",
            "  0.98431373 0.99607843 0.94901961 0.9254902  0.91372549 0.89019608\n",
            "  0.85882353 0.79215686 0.75686275 0.74117647 0.72941176 0.70980392\n",
            "  0.67058824 0.64705882 0.74509804 0.16470588]\n",
            " [0.30196078 0.78039216 0.6745098  0.7372549  0.78039216 0.79215686\n",
            "  0.85490196 0.85882353 0.8627451  0.89803922 0.91764706 0.87058824\n",
            "  0.83529412 0.81960784 0.81176471 0.82352941 0.79607843 0.72156863\n",
            "  0.59607843 0.67058824 0.64705882 0.63529412 0.63529412 0.65490196\n",
            "  0.65882353 0.61568627 0.75294118 0.30588235]\n",
            " [0.         0.17647059 0.39607843 0.54901961 0.62352941 0.68235294\n",
            "  0.71372549 0.72941176 0.7254902  0.7372549  0.76470588 0.77254902\n",
            "  0.7372549  0.68627451 0.52156863 0.2745098  0.0745098  0.\n",
            "  0.         0.81960784 0.90588235 0.85490196 0.87058824 0.87843137\n",
            "  0.89019608 0.85098039 0.89803922 0.36470588]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.00784314 0.09411765 0.14509804 0.17647059 0.1254902  0.07058824\n",
            "  0.04313725 0.         0.         0.         0.         0.\n",
            "  0.         0.28235294 0.2        0.20784314 0.14509804 0.13333333\n",
            "  0.11372549 0.12156863 0.01960784 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UifWCbN66TOR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Building the Neural Network model\n",
        "\n",
        "model_nn = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                      tf.keras.layers.Dense(150,activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(10,activation=tf.nn.softmax)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N4LHBou87f5D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "dfe78dbf-feae-46ed-bfd5-0b0cb87e3593"
      },
      "cell_type": "code",
      "source": [
        "## Compiling the model\n",
        "\n",
        "model_nn.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "                 loss = 'sparse_categorical_crossentropy',\n",
        "                metrics =['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model_nn.fit(train_feature, train_label ,epochs= 10)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2785 - acc: 0.8963\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.2657 - acc: 0.9006\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2541 - acc: 0.9057\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2443 - acc: 0.9093\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2362 - acc: 0.9115\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2296 - acc: 0.9146\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2216 - acc: 0.9169\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2146 - acc: 0.9190\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2073 - acc: 0.9219\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2014 - acc: 0.9247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe88dc2c588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "yhW2soL78doM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8b0e2f9f-55f1-4483-d4f9-7e2e199dbc3f"
      },
      "cell_type": "code",
      "source": [
        "## Lets Evaluate the model on test data\n",
        "\n",
        "model_nn.evaluate(test_feature,test_label)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 64us/sample - loss: 0.3490 - acc: 0.8840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3489769461274147, 0.884]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "lBf2Lf7U_Yib",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ctGBtY2h_3Zz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Few exercises"
      ]
    },
    {
      "metadata": {
        "id": "ccXVQr2P_-Yn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## predict the labels for the test data\n",
        "\n",
        "classification_predictions = model_nn.predict(test_feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "khor6A8cARIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f7a4e636-cd49-49d1-ff2e-b65a8840fb68"
      },
      "cell_type": "code",
      "source": [
        "## Print the labels\n",
        "print(classification_predictions[1])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.4879460e-05 3.5395882e-20 9.9834728e-01 4.7278709e-17 1.3141693e-03\n",
            " 4.0314941e-13 2.9371501e-04 2.3787483e-16 2.4234373e-11 3.7884879e-17]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yvan-uu6AacO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3702b6a-c637-4825-d28b-afb37d25a157"
      },
      "cell_type": "code",
      "source": [
        "print(test_label[1])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XZeyPC3jBaCO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see the predictions returns the probablities of every class for this class starting from class 0 to 9 in the list and we can see that label at position 1 has the highest probablity indicating it has predicted corrected the actual label is also 1"
      ]
    },
    {
      "metadata": {
        "id": "cfM3Fs-vB14i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9TeUqHdtCvBW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercise 2"
      ]
    },
    {
      "metadata": {
        "id": "9IrnVGT0Cyay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "90df82ec-daab-443f-8d7f-b4986cb14189"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "import time\n",
        "t0 = time.time()\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "t1= time.time()\n",
        "\n",
        "print(\" The total time taken\",(t1-t0)/60.0)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 29s 482us/sample - loss: 0.1863\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 29s 489us/sample - loss: 0.0734\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 30s 494us/sample - loss: 0.0494\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 29s 489us/sample - loss: 0.0340\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 28s 472us/sample - loss: 0.0264\n",
            " The total time taken 145.94455456733704\n",
            "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0757\n",
            "[2.7848188e-09 5.9413766e-11 2.5733979e-07 1.9469837e-05 2.6841386e-16\n",
            " 4.2909193e-08 1.1875009e-14 9.9997926e-01 1.0054608e-07 1.0288871e-06]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J2u2OjT2GCKw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "7ZsYImv9GFXq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Earlier when you trained for extra epochs you had an issue where your loss might change. It might have taken a bit of time for you to wait for the training to do that, and you might have thought 'wouldn't it be nice if I could stop the training when I reach a desired value?' -- i.e. 95% accuracy might be enough for you, and if you reach that after 3 epochs, why sit around waiting for it to finish a lot more epochs....So how would you fix that? Like any other program...you have callbacks! Let's see them in action..."
      ]
    },
    {
      "metadata": {
        "id": "03w_gMw1GHap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "b9eafd27-9b29-48cc-e209-02390a548393"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self , epoch , logs={}):\n",
        "    if(logs.get('loss')<0.1):\n",
        "      print(\"\\n Reached 70% accuracy so cancelling training !!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks1 = myCallback()\n",
        "  \n",
        "\n",
        "import time\n",
        "t0 = time.time()\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "             metrics =['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5,callbacks=[callbacks1])\n",
        "t1= time.time()\n",
        "\n",
        "print(\" The total time taken\",(t1-t0)/60.0)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 9s 158us/sample - loss: 0.2600 - acc: 0.9256\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 9s 148us/sample - loss: 0.1171 - acc: 0.9649\n",
            "Epoch 3/5\n",
            "59616/60000 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9762\n",
            " Reached 70% accuracy so cancelling training !!\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0794 - acc: 0.9762\n",
            " The total time taken 0.44547748963038125\n",
            "10000/10000 [==============================] - 1s 50us/sample - loss: 0.0927 - acc: 0.9709\n",
            "[4.7892360e-07 4.9277830e-08 6.7365567e-05 1.1657174e-03 1.1260277e-09\n",
            " 1.4111496e-06 6.1436441e-13 9.9875212e-01 1.4912174e-06 1.1384996e-05]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NJXR2aa2JuIY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}